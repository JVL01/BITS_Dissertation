# BITS_Dissertation
Application of Prompt Engineering using NLP in generating Programming Code


# ğŸ“Œ Project Overview
This project explores the **application of Prompt Engineering and NLP** for **automatic code generation** in Python and Java. The primary objective is to **enhance code generation capabilities** using advanced **prompt engineering techniques** such as:
- **Zero-Shot Learning (ZSL)**
- **Few-Shot Learning (FSL)**
- **Chain-of-Thought (CoT)**
- **Tree-of-Thought (ToT)**
- **Instruction-Based Prompting**

**Retrieval-Augmented Generation (RAG)** is integrated with **FAISS indexing** to improve contextual accuracy before code generation.

---

## ğŸ” Key Features
âœ” **Utilizes multiple datasets**: CodeParrot, CodeXGLUE (Python & Java)  
âœ” **Implements Prompt Engineering Techniques**  
âœ” **Retrieval-Augmented Generation (RAG) with FAISS** for relevant context retrieval  
âœ” **Fine-tuned models** on Python, Java, and CodeParrot dataset  
âœ” **Uses CodeT5/FLAN-T5 for prompt refinement**  
âœ” **Evaluates generated code using BLEU, ROUGE, and CodeBLEU**  
âœ” **Streamlit UI Integration** (Prototype - Not Fully Functional)  

---

## ğŸ“‚ Project Structure
```
ğŸ“¦ Project-Repo
 â”£ ğŸ“‚ datasets/             # Python, Java, and CodeParrot datasets
 â”£ ğŸ“‚ models/               # Pretrained and fine-tuned models
 â”£ ğŸ“‚ notebooks/            # Google Colab Notebooks
 â”£ ğŸ“‚ scripts/              # Python scripts for training and evaluation
 â”£ ğŸ“‚ faiss_index/          # FAISS embeddings for code retrieval
 â”£ ğŸ“‚ outputs/              # Generated code and evaluation metrics
 â”£ ğŸ“œ README.md             # Project Documentation
 â”£ ğŸ“œ requirements.txt      # Dependencies
 â”— ğŸ“œ app.py                # Streamlit UI script (Prototype)
```

---

## ğŸ› ï¸ Installation & Setup
To run this project, follow these steps:

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name
```

### 2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run Model Training
Train the fine-tuned model using:
```bash
python scripts/train_model.py
```

### 4ï¸âƒ£ Run FAISS Retrieval
To index and retrieve relevant code snippets:
```bash
python scripts/faiss_retrieval.py
```

### 5ï¸âƒ£ Run Streamlit UI
Launch the interactive UI (prototype):
```bash
streamlit run app.py
```

---

## ğŸ“Š Evaluation Metrics
The generated code is evaluated using the following metrics:
- **BLEU Score**: Measures the n-gram overlap between generated and reference code.
- **ROUGE Score**: Evaluates the recall-oriented similarity.
- **CodeBLEU Score**: Measures syntax correctness and code structure similarity.

---

## ğŸ”¬ Research & Findings
- Prompt engineering techniques significantly influence **code quality**.
- RAG with FAISS **improves contextual accuracy**.
- CodeT5/FLAN-T5 helps in **refining vague prompts**.
- The Streamlit-based chatbot **did not yield effective results** due to model limitations.

---

## ğŸš€ Future Work
- **Improve RAG retrieval quality** using better embeddings.
- **Experiment with GPT-4 & StarCoder** for better code generation.
- **Enhance prompt engineering techniques** with self-refinement.
- **Develop a more interactive and robust UI** for usability.


